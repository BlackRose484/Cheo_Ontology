import { Request, Response } from "express";
import { AIModelFactory, AIModel } from "../services/ai/aiModelFactory";

export class AIController {
  static async handleChat(req: Request, res: Response) {
    try {
      const {
        message,
        context = [],
        model = "gemini-2.5-flash",
        conversationId,
      } = req.body;

      if (!message) {
        return res.status(400).json({
          error: "Message is required",
          response: "Vui l√≤ng nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n v·ªÅ ngh·ªá thu·∫≠t Ch√®o! üé≠",
        });
      }

      const response = await AIModelFactory.processQuery(
        message,
        AIModel.GEMINI,
        context,
        model
      );

      // Add metadata
      const result = {
        ...response,
        timestamp: new Date().toISOString(),
        conversationId: conversationId || Date.now().toString(),
      };

      res.json(result);
    } catch (error) {
      console.error("AI Chat error:", error);
      res.status(500).json({
        error: "Internal server error",
        response: "Xin l·ªói, t√¥i g·∫∑p s·ª± c·ªë k·ªπ thu·∫≠t. Vui l√≤ng th·ª≠ l·∫°i sau! üé≠",
        suggestions: [
          "T√¨m nh√¢n v·∫≠t trong Ch√®o",
          "C√°c v·ªü Ch√®o n·ªïi ti·∫øng",
          "Di·ªÖn vi√™n Ch√®o",
        ],
        intent: "error",
        confidence: 0,
        model: "error",
        timestamp: new Date().toISOString(),
      });
    }
  }

  static async getAvailableModels(req: Request, res: Response) {
    try {
      const allModels = AIModelFactory.getAllSupportedModels();
      const modelInfo = allModels.map((modelName) => ({
        id: modelName,
        name: modelName,
        service: AIController.getServiceForModel(modelName),
        available: true,
      }));

      res.json({
        models: modelInfo,
        default: "gemini-2.5-flash",
        count: modelInfo.length,
      });
    } catch (error) {
      res.status(500).json({
        error: "Failed to get available models",
      });
    }
  }

  static async getSuggestions(req: Request, res: Response) {
    try {
      const suggestions = [
        "T√¨m nh√¢n v·∫≠t n·ªØ trong Ch√®o",
        "V·ªü Ch√®o n√†o n·ªïi ti·∫øng nh·∫•t?",
        "Di·ªÖn vi√™n n√†o ƒë√≥ng vai Th·ªã M·∫ßu?",
        "C·∫£m x√∫c bu·ªìn xu·∫•t hi·ªán trong tr√≠ch ƒëo·∫°n n√†o?",
        "Gi·ªõi thi·ªáu v·ªÅ l·ªãch s·ª≠ ngh·ªá thu·∫≠t Ch√®o",
        "T√¨m c√°c v·ªü Ch√®o c√≥ ch·ªß ƒë·ªÅ t√¨nh y√™u",
        "Nh√¢n v·∫≠t n√†o c√≥ nhi·ªÅu c·∫£m x√∫c nh·∫•t?",
        "So s√°nh nh√¢n v·∫≠t nam v√† n·ªØ trong Ch√®o",
        "C√°c lo·∫°i c·∫£m x√∫c trong Ch√®o",
        "Di·ªÖn vi√™n Ch√®o n·ªïi ti·∫øng",
      ];

      // Shuffle suggestions for variety
      const shuffled = suggestions.sort(() => 0.5 - Math.random());

      res.json({
        suggestions: shuffled.slice(0, 6), // Return 6 random suggestions
        total: suggestions.length,
      });
    } catch (error) {
      console.error("Error getting suggestions:", error);
      res.status(500).json({
        error: "Failed to get suggestions",
        suggestions: [
          "T√¨m nh√¢n v·∫≠t trong Ch√®o",
          "C√°c v·ªü Ch√®o n·ªïi ti·∫øng",
          "Di·ªÖn vi√™n Ch√®o",
        ],
      });
    }
  }

  private static getServiceForModel(modelName: string): string {
    if (modelName.includes("gemini")) {
      return "Google Gemini";
    }
    // Add more services as they become available
    return "Unknown Service";
  }

  private static getModelDisplayName(model: AIModel): string {
    const names: { [key: string]: string } = {
      [AIModel.GEMINI]: "Google Gemini",
      [AIModel.OPENAI]: "OpenAI GPT",
      [AIModel.CLAUDE]: "Anthropic Claude",
      [AIModel.CUSTOM]: "Custom Model",
    };
    return names[model] || model;
  }
}
